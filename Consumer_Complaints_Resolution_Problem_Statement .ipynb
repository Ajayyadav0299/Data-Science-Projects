{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer Complaints Resolution\n",
    "\n",
    "\n",
    "Consumer complaint resolution is important to any business. In this particular case we have been given details consumer complaints along with whether consumer disputed with the conclusion. If we are able to predict this , consumer likely disputed can be given more attention as to how the complaints are handelled as well as how to convincingly convey the final conlusions to them.\n",
    "\n",
    "Your target here is to build prediction model for colum \"Consumer disputed\"\n",
    "\n",
    "* Training Data = 'Consumer_Complaints_train.csv'\n",
    "* Test Data = 'Consumer_Complaints_test.csv\"\n",
    "\n",
    "All the column names are sefl explanatory.You need to build your model on Train data . Test data doesnt have response column 'Consumer disputed', you need to predict those values and submit it a csv format.\n",
    "\n",
    "Column names ,value types should exactly match. Also number of rows in the submission csv should be exactly same as test data. \n",
    "\n",
    "Your submission should have AUC score atleast 0.54.\n",
    "\n",
    "Few Suggestions Before you begin:\n",
    "\n",
    "* Do not use date columns as is , you can use them to create other features. For example which month of the year complaint was filed. Was it first week or last week of the month. How long it took between complaint filing and data being sent to the company. These are just ideas , feel free to make any other features out of these. You can convert strings/object type columns to date_time data using pd.to_datetime.\n",
    "\n",
    "* It doesnt make sense to use Consumer ID  as predictor.\n",
    "\n",
    "* Break your train data into two parts and use one to build model and test its performance on the other. This way you will have some idea on your approx score that you might recieve on your submission. Otherwise you'll have to wait for few days post submission without knowing whether you are going to do well or not; or whether your solution needs improvement or not\n",
    "\n",
    "* Before removing NAs from data, do check if there are columns which have too many NaN. See whether you need to impute those values or need to drop that column all together; before you start removing NA obs from the entire data.\n",
    "\n",
    "* If you are creating any new features on your training data or modifying features in the train; you will have to do that for test data also , in order to use the model which you built on test data for making prediction.\n",
    "\n",
    "* It doesnt make sense to use ZIP CODES as a numeric variable\n",
    "\n",
    "* Its a large dataset , might take a lot of time to run\n",
    "\n",
    "* Consider making features for prsesence of NaNs itself\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
